#' Request metadata for all dataflows in specified workspace
#'
#' @param workspace Name of the workspace containing dataflows
#' @param powerbi_token AzureAuth token object generated by `get_powerbi_token()`
#'
#' @return DataFrame containing the names, GUIDs, and descriptions for all dataflows in workspace
#' @export
list_dataflows <- function(workspace, powerbi_token) {
  workspace_metadata <- list_workspaces(powerbi_token)
  if (!(workspace %in% workspace_metadata$Workspace)) {
    stop("No workspace called: ", workspace, " in tenant!", call. = FALSE)
  }

  base_url <- "https://api.powerbi.com/v1.0/myorg/groups/"
  workspace_id <- workspace_metadata[workspace_metadata$Workspace == workspace,]$WorkspaceId
  workspace_request <-  httr::GET(url = paste0(base_url, workspace_id, "/dataflows"),
                                config = get_auth_header(powerbi_token),
                                httr::content_type_json())

  if (workspace_request$status_code != 200) {
    stop("API request returned status code: ", workspace_request$status_code, "!",
         call. = TRUE)
  }

  metadata_content <- httr::content(workspace_request)$value

  content_to_dataframe <- purrr::map_dfr(metadata_content, \(metadata){
    do.call(data.frame, purrr::keep(metadata, \(x){length(x) > 0}))
  })
  content_to_dataframe$Workspace <- workspace
  content_to_dataframe$WorkspaceId <- workspace_id

  content_to_dataframe <- content_to_dataframe[,c("Workspace", "WorkspaceId", "name", "objectId", "description", "configuredBy")]
  names(content_to_dataframe) <- c("Workspace", "WorkspaceId", "Dataflow", "DataflowId","DataflowDescription", "DataflowOwner")
  content_to_dataframe
}

#' Request metadata for all tables in a specified dataflow in specified workspace
#'
#' @param workspace Name of the workspace containing dataflow
#' @param dataflow Name of the dataflow containing tables
#' @param powerbi_token AzureAuth token object generated by `get_powerbi_token()`
#'
#' @return DataFrame containing the names, column names, and column types, for all tables in dataflow
#' @export
list_dataflow_tables <- function(workspace, dataflow, powerbi_token) {
  dataflow_metadata <- list_dataflows(workspace, powerbi_token)
  if (!(dataflow %in% dataflow_metadata$Dataflow)) {
    stop("No dataflow called: ", dataflow, " in workspace: ", workspace, "!",
         call. = FALSE)
  }
  target_dataflow <- dataflow_metadata[dataflow_metadata$Dataflow == dataflow,]

  base_url <- "https://api.powerbi.com/v1.0/myorg/groups/"
  table_request <-
    httr::GET(url = paste0(base_url, target_dataflow$WorkspaceId, "/dataflows/", target_dataflow$DataflowId),
              config = get_auth_header(powerbi_token),
              httr::content_type_json())

  if (table_request$status_code != 200) {
    stop("API request returned status code: ", table_request$status_code, "!",
         call. = TRUE)
  }

  metadata_content <- httr::content(table_request)
  purrr::map_dfr(metadata_content$entities, \(entity) {
    loc_url <- entity$partitions[[1]]$location
    data.frame(
      Workspace = target_dataflow$Workspace,
      WorkspaceId = target_dataflow$WorkspaceId,
      Dataflow = target_dataflow$Dataflow,
      DataflowId = target_dataflow$DataflowId,
      Table = entity$name,
      ColumnNames = paste0(purrr::map_chr(entity$attributes, "name"), collapse=","),
      ColumnTypes = paste0(purrr::map_chr(entity$attributes, "dataType"), collapse=","),
      FileLocation = strsplit(loc_url, "?", fixed = TRUE)[[1]][1]
    )
  })
}

#' Request the Azure Blob SaS key needed to download a specified dataflow table
#'
#' @param workspace Name of the workspace containing dataflow
#' @param dataflow Name of the dataflow containing tables
#' @param table Name of the table to download
#' @param powerbi_token AzureAuth token object generated by `get_powerbi_token()`
#'
#' @return DataFrame containing table metadata and SaS key
#' @export
get_table_sas_key <- function(workspace, dataflow, table, powerbi_token) {
  table_metadata <- list_dataflow_tables(workspace, dataflow, powerbi_token)
  if (!(table %in% table_metadata$Table)) {
    stop("No table called: ", table, " found in dataflow called: ", dataflow, " in workspace: ", workspace, "!",
         call. = FALSE)
  }
  target_table <- table_metadata[table_metadata$Table == table, ]

  auth_header <- get_auth_header(powerbi_token)
  base_url <- "https://api.powerbi.com/v1.0/myorg/groups/"
  metadata_request <- httr::GET(url = base_url,
                                config = auth_header,
                                httr::content_type_json())

  if (metadata_request$status_code != 200) {
    stop("API request returned status code: ", metadata_request$status_code, "!",
         call. = TRUE)
  }

  pbi_url_base <- httr::content(metadata_request)$`@odata.context`
  pbi_url <- strsplit(pbi_url_base, split = "v1.0/", fixed = TRUE)[[1]][1]
  pbi_url_https <- gsub(pattern = "http:", replacement = "https:", x = pbi_url)

  sas_url <- paste0(pbi_url_https, "metadata/v201606/cdsa/dataflows/",
                    target_table$DataflowId, "/storageAccess")

  body_list = list(
    "TokenLifetimeInMinutes" = 10,
    "Permissions" = "Read",
    "EntityName" = target_table$Table
  )

  sas_query <- httr::POST(url = sas_url,
                body = jsonlite::toJSON(body_list, auto_unbox = TRUE),
                config = auth_header,
                httr::content_type_json())

  if (sas_query$status_code != 200) {
    stop("SAS API request returned status code: ", sas_query$status_code, "!",
         call. = TRUE)
  }

  sas_content <- httr::content(sas_query)
  target_table$SasKey <- sas_content$accessDetails[[1]]$blobContainerSas
  target_table
}

#' Download a specified dataflow table into R
#'
#' @param workspace Name of the workspace containing dataflow
#' @param dataflow Name of the dataflow containing tables
#' @param table Name of the table to download
#' @param powerbi_token AzureAuth token object generated by `get_powerbi_token()`
#'
#' @return DataFrame containing downloaded table
#' @export
get_dataflow_table <- function(workspace, dataflow, table,
                                powerbi_token = get_powerbi_token()) {
  table_access_data <- get_table_sas_key(workspace, dataflow, table, powerbi_token)

  column_names <- strsplit(table_access_data$ColumnNames, ",", fixed = TRUE)[[1]]
  table_url <- paste0(table_access_data$FileLocation, "?", table_access_data$SasKey)
  readr::read_csv(file = table_url,
                  col_names = column_names,
                  show_col_types = FALSE)
}
